# Proyecto de IngenierÃ­a de Datos en Databricks

## ğŸ“ TecnologÃ­a principal: Databricks + Delta Lake + Apache Spark + Azure

## Overview
In this project, I built an ETL job in Databricks using PySpark with a Medallion architecture (Bronze, Silver, Gold) to process sales data from .csv files stored in Azure Data Lake Storage Gen2. âœ…

## Map
```
databricks-etl-project/
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/                # Datos crudos ingeridos desde Azure Data Lake
â”‚   â”‚   â”œâ”€â”€ clientes.csv
â”‚   â”‚   â”œâ”€â”€ productos.csv
â”‚   â”‚   â”œâ”€â”€ categorias.csv
â”‚   â”‚   â””â”€â”€ ventas.csv
â”‚   â”œâ”€â”€ silver/                # Datos limpios y transformados
â”‚   â”‚   â”œâ”€â”€ clientes_autoloader.delta
â”‚   â”‚   â”œâ”€â”€ productos_autoloader.delta
â”‚   â”‚   â”œâ”€â”€ categorias_autoloader.delta
â”‚   â”‚   â””â”€â”€ ventas_autoloader.delta
â”‚   â””â”€â”€ gold/                  # Datos consolidados listos para analÃ­tica
â”‚       â””â”€â”€ tabla_consolidada.delta
â”œâ”€â”€ notebooks/                 # Notebooks en Databricks
â”‚   â”œâ”€â”€ taller_autoloader.ipynb
â””â”€â”€ img/                       # Scripts de apoyo en PySpark
    â””â”€â”€job_detail.jpg
â””â”€â”€cluster
â””â”€â”€libs
```

## Scripts Description
taller_autoloader.ipynb: Extracts raw data from csv in Azure Storage Gen2. âœ…

## Jobs & Pipelines
The jobs (clientes, ventas, categorias, productos) are configured with the following parameters: {"location":"clientes","table_name":"clientes_autoloader"} âœ…
