# Proyecto de IngenierÃ­a de Datos en Databricks

## ğŸ“ TecnologÃ­a principal: Databricks + Delta Lake + Apache Spark + Azure

## Overview
In this project, I built an ETL job in Databricks using PySpark with a Medallion architecture (Bronze, Silver, Gold) to process sales data from .csv files stored in Azure Data Lake Storage Gen2. âœ…

## Map
```
databricks-etl-project/
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/                # Datos crudos ingeridos desde Azure Data Lake
â”‚   â”‚   â”œâ”€â”€ clientes.csv
â”‚   â”‚   â”œâ”€â”€ productos.csv
â”‚   â”‚   â”œâ”€â”€ categorias.csv
â”‚   â”‚   â””â”€â”€ ventas.csv
â”‚   â”œâ”€â”€ silver/                # Datos limpios y transformados
â”‚   â”‚   â”œâ”€â”€ clientes_silver.delta
â”‚   â”‚   â”œâ”€â”€ productos_silver.delta
â”‚   â”‚   â”œâ”€â”€ categorias_silver.delta
â”‚   â”‚   â””â”€â”€ ventas_silver.delta
â”‚   â””â”€â”€ gold/                  # Datos consolidados listos para analÃ­tica
â”‚       â””â”€â”€ modelo_ventas.delta
â”œâ”€â”€ notebooks/                 # Notebooks en Databricks
â”‚   â”œâ”€â”€ taller_autoloader.ipynb
â””â”€â”€ img/                       # Scripts de apoyo en PySpark
    â”œâ”€â”€ etl_job.py
    â”œâ”€â”€ transformations.py
    â””â”€â”€ utils.py
```

## Scripts Description
Taller Autoloader.py: Extracts raw data from csv in Azure Storage Gen2.

## Jobs & Pipelines
The jobs are configured with the following parameters: {"location":"clientes","table_name":"clientes_autoloader"} âœ…
